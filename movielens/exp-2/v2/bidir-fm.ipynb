{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ee818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fdaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import copy\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0879a71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset: 893 users, 50 movies\n",
      "Sparsity: 72.08%\n"
     ]
    }
   ],
   "source": [
    "# Load the MovieLens 100K dataset\n",
    "# Assuming the file is 'u.data' in the same directory\n",
    "# Columns: user_id, movie_id, rating, timestamp\n",
    "data = pd.read_csv('u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "data['rating'] = data['rating'] - 2\n",
    "data = data[data['rating'] > 0]\n",
    "\n",
    "# Step 0: only select top 50 movies\n",
    "valid_movies = np.array(data['movie_id'].value_counts().index[:50])\n",
    "data = data[data['movie_id'].isin(valid_movies)]\n",
    "\n",
    "# Step 1: Remove users s.t. count >= 2 * unique timestamp\n",
    "temp = data.groupby('user_id')['timestamp'].agg(['count', 'nunique']).reset_index()\n",
    "valid_users = temp[temp['count']/temp['nunique'] < 2]['user_id']\n",
    "data = data[data['user_id'].isin(valid_users)]\n",
    "\n",
    "# Step 2: Remove users with only 1 rating\n",
    "temp = data['user_id'].value_counts() \n",
    "one_rating = np.array(temp[temp == 1].index)\n",
    "data = data[~data['user_id'].isin(one_rating)]\n",
    "\n",
    "# Step 3: Deduplicate and recode\n",
    "data = data.groupby(['user_id', 'timestamp'], group_keys=False).apply(lambda group: group.sample(n=1, random_state=42))\n",
    "data = data.sort_values(['user_id', 'timestamp']).reset_index(drop = True)\n",
    "data['movie_id'] = pd.factorize(data['movie_id'])[0] + 1\n",
    "\n",
    "num_users = data['user_id'].nunique()\n",
    "num_movies = data['movie_id'].nunique()\n",
    "num_ratings = len(data)\n",
    "\n",
    "sparsity = 1 - (num_ratings / (num_users * num_movies))\n",
    "\n",
    "print(f\"Filtered Dataset: {num_users} users, {num_movies} movies\")\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be35ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "all_users = data['user_id'].unique()\n",
    "shuffled_indices = np.random.permutation(len(all_users))\n",
    "\n",
    "midpoint = 3 * len(all_users) // 4\n",
    "indices_1 = shuffled_indices[:midpoint]\n",
    "indices_2 = shuffled_indices[midpoint:]\n",
    "\n",
    "train_users = shuffled_indices[indices_1]\n",
    "test_users = shuffled_indices[indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b553a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['user_id'].isin(train_users)].reset_index(drop = True)\n",
    "data_test = data[data['user_id'].isin(test_users)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a3c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    center = []\n",
    "    movie = []\n",
    "    rating = []\n",
    "    length = []\n",
    "    target = []\n",
    "    \n",
    "    unique_user_ids = df['user_id'].unique()\n",
    "    \n",
    "    for user_id in unique_user_ids:\n",
    "\n",
    "        temp = df[df['user_id'] == user_id]\n",
    "        movie_list, rating_list = list(temp['movie_id']), list(temp['rating'])\n",
    "        center += movie_list\n",
    "        target += rating_list\n",
    "        \n",
    "        for idx in range(temp.shape[0]):\n",
    "            movie.append(movie_list[:idx] + movie_list[(idx+1):])\n",
    "            rating.append(rating_list[:idx] + rating_list[(idx+1):])\n",
    "            length.append(temp.shape[0] - 1)\n",
    "            \n",
    "    return center, movie, rating, length, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d7fcf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "center_train, movie_train, rating_train, length_train, target_train \\\n",
    "    = preprocess_data(data_train)\n",
    "\n",
    "center_test, movie_test, rating_test, length_test, target_test \\\n",
    "    = preprocess_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aead9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_train, center_val, movie_train, movie_val, rating_train, rating_val, \\\n",
    "length_train, length_val, target_train, target_val = train_test_split(\n",
    "    center_train, movie_train, rating_train, length_train, target_train, \n",
    "    test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78e4d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887b5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d70ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ctx = max(length_train + length_test + length_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47eaa47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_train = [movie + [0] * (max_ctx - len(movie)) if len(movie) < max_ctx \n",
    "               else movie[:max_ctx] for movie in movie_train]\n",
    "\n",
    "movie_val = [movie + [0] * (max_ctx - len(movie)) if len(movie) < max_ctx \n",
    "               else movie[:max_ctx] for movie in movie_val]\n",
    "\n",
    "movie_test = [movie + [0] * (max_ctx - len(movie)) if len(movie) < max_ctx \n",
    "               else movie[:max_ctx] for movie in movie_test]\n",
    "\n",
    "rating_train = [rating + [0] * (max_ctx - len(rating)) if len(rating) < max_ctx \n",
    "               else rating[:max_ctx] for rating in rating_train]\n",
    "\n",
    "rating_val = [rating + [0] * (max_ctx - len(rating)) if len(rating) < max_ctx \n",
    "               else rating[:max_ctx] for rating in rating_val]\n",
    "\n",
    "rating_test = [rating + [0] * (max_ctx - len(rating)) if len(rating) < max_ctx \n",
    "               else rating[:max_ctx] for rating in rating_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92a84b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_train_data = np.array(center_train)  # Center movie\n",
    "context_train_data = np.array(movie_train)  # Context movies\n",
    "rating_train_data = np.array(rating_train)  # Context ratings\n",
    "length_train_data = np.array(length_train)  # Length of the context\n",
    "target_train_data = np.array(target_train)  # Target rating\n",
    "\n",
    "center_val_data = np.array(center_val)  # Center movie\n",
    "context_val_data = np.array(movie_val)  # Context movies\n",
    "rating_val_data = np.array(rating_val)  # Context ratings\n",
    "length_val_data = np.array(length_val)  # Length of the context\n",
    "target_val_data = np.array(target_val)  # Target rating\n",
    "\n",
    "center_test_data = np.array(center_test)  # Center movie\n",
    "context_test_data = np.array(movie_test)  # Context movies\n",
    "rating_test_data = np.array(rating_test)  # Context ratings\n",
    "length_test_data = np.array(length_test)  # Length of the context\n",
    "target_test_data = np.array(target_test)  # Target rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e910b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5304 - val_loss: 0.5328\n",
      "Epoch 2/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5250 - val_loss: 0.5327\n",
      "Epoch 3/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5323 - val_loss: 0.5326\n",
      "Epoch 4/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5308 - val_loss: 0.5325\n",
      "Epoch 5/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5321 - val_loss: 0.5323\n",
      "Epoch 6/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5402 - val_loss: 0.5320\n",
      "Epoch 7/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5305 - val_loss: 0.5316\n",
      "Epoch 8/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5315 - val_loss: 0.5312\n",
      "Epoch 9/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5288 - val_loss: 0.5306\n",
      "Epoch 10/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5342 - val_loss: 0.5298\n",
      "Epoch 11/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5350 - val_loss: 0.5289\n",
      "Epoch 12/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5304 - val_loss: 0.5279\n",
      "Epoch 13/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5302 - val_loss: 0.5268\n",
      "Epoch 14/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5257 - val_loss: 0.5257\n",
      "Epoch 15/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5147 - val_loss: 0.5245\n",
      "Epoch 16/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5217 - val_loss: 0.5234\n",
      "Epoch 17/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5303 - val_loss: 0.5225\n",
      "Epoch 18/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5129 - val_loss: 0.5217\n",
      "Epoch 19/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5148 - val_loss: 0.5211\n",
      "Epoch 20/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5209 - val_loss: 0.5206\n",
      "Epoch 21/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5151 - val_loss: 0.5203\n",
      "Epoch 22/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5055 - val_loss: 0.5201\n",
      "Epoch 23/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5246 - val_loss: 0.5200\n",
      "Epoch 24/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5040 - val_loss: 0.5199\n",
      "Epoch 25/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5147 - val_loss: 0.5199\n",
      "Epoch 26/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5243 - val_loss: 0.5199\n",
      "Epoch 27/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5262 - val_loss: 0.5199\n",
      "Epoch 28/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5089 - val_loss: 0.5199\n",
      "Epoch 29/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5074 - val_loss: 0.5200\n",
      "Epoch 30/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5177 - val_loss: 0.5200\n",
      "Epoch 31/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5259 - val_loss: 0.5200\n",
      "Epoch 32/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5147 - val_loss: 0.5200\n",
      "Epoch 33/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5100 - val_loss: 0.5200\n",
      "Epoch 34/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5193 - val_loss: 0.5200\n",
      "Epoch 35/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5206 - val_loss: 0.5200\n",
      "Epoch 36/1000\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5185 - val_loss: 0.5200\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "input_dim = data['movie_id'].nunique() + 1\n",
    "\n",
    "center_input = layers.Input(shape=(1,), dtype=tf.int32, name=\"center_input\")  \n",
    "context_input = layers.Input(shape=(max_ctx,), dtype=tf.int32, name=\"context_input\")  \n",
    "rating_input = layers.Input(shape=(max_ctx,), dtype=tf.float32, name=\"rating_input\")  \n",
    "length_input = layers.Input(shape=(1,), dtype=tf.float32, name=\"length_input\") \n",
    "\n",
    "movie_embedding = layers.Embedding(input_dim=input_dim, output_dim=embedding_size)(context_input)\n",
    "center_embedding = layers.Embedding(input_dim=input_dim, output_dim=embedding_size)(center_input)\n",
    "\n",
    "rating_input = layers.Reshape((max_ctx, 1))(rating_input)\n",
    "weighted_embeddings = layers.Multiply()([movie_embedding, rating_input])\n",
    "\n",
    "sum_embeddings = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1), name=\"sum_embeddings\")(weighted_embeddings)\n",
    "\n",
    "average_embeddings = layers.Lambda(lambda inputs: inputs[0] / inputs[1], name=\"average_embeddings\")(\n",
    "    [sum_embeddings, length_input]\n",
    ")\n",
    "\n",
    "center_embedding_flat = layers.Flatten()(center_embedding)\n",
    "lambda_output = layers.Dot(axes=-1, name=\"dot_product\")([average_embeddings, center_embedding_flat])\n",
    "lambda_output_exp = layers.Activation('exponential', name=\"lambda_output_exp\")(lambda_output)\n",
    "\n",
    "model = Model(inputs=[center_input, context_input, rating_input, length_input], outputs=lambda_output_exp)\n",
    "\n",
    "\n",
    "#### score follows a Poisson distribution with mean 1 + exp(.)\n",
    "\n",
    "def poisson_log_likelihood(y_true, y_pred):\n",
    "    epsilon = 1e-8\n",
    "    return tf.reduce_mean(1 + y_pred - y_true * tf.math.log(1 + y_pred))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 1e-4), loss=poisson_log_likelihood)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    \n",
    "    patience=10,  \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "# Fit the model with validation data and early stopping\n",
    "history = model.fit(\n",
    "    [center_train_data, context_train_data, rating_train_data, length_train_data], \n",
    "    target_train_data,        \n",
    "    validation_data=([center_val_data, context_val_data, rating_val_data, length_val_data], target_val_data),  \n",
    "    epochs=1000,                 \n",
    "    batch_size=256,            \n",
    "    callbacks=[early_stopping] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a045021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.4807\n",
      "Test Loss: 0.5072845816612244\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate([center_test_data, context_test_data, rating_test_data, length_test_data], target_test_data)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ad9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test_ratings = model.predict([center_test_data, context_test_data, rating_test_data, length_test_data]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e49b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(target_test_data, pred_test_ratings + 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ad15de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0592453, 2.0995686, 2.2093077)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_test_ratings + 1)[target_test_data == 1].mean(), \\\n",
    "    (pred_test_ratings + 1)[target_test_data == 2].mean(), \\\n",
    "        (pred_test_ratings + 1)[target_test_data == 3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7d1d876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │ context_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ keras_tensor_2CLONE │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ keras_tensor_2CL… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ center_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sum_embeddings      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ length_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │ center_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_embeddings  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sum_embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ length_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_embeddin… │\n",
       "│                     │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_output_exp   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_product[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,632\u001b[0m │ context_input[\u001b[38;5;34m1\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ keras_tensor_2CLONE │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ keras_tensor_2CL… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ center_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sum_embeddings      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ length_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m1,632\u001b[0m │ center_input[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_embeddings  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sum_embeddings[\u001b[38;5;34m1\u001b[0m… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ length_input[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ average_embeddin… │\n",
       "│                     │                   │            │ flatten[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_output_exp   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot_product[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,794</span> (38.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,794\u001b[0m (38.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,264</span> (12.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,264\u001b[0m (12.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,530</span> (25.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,530\u001b[0m (25.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
