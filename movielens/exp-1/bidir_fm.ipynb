{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0653b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e4c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import copy\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee580ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset: 902 users, 50 movies\n",
      "Sparsity: 69.50%\n"
     ]
    }
   ],
   "source": [
    "# Load the MovieLens 100K dataset\n",
    "# Assuming the file is 'u.data' in the same directory\n",
    "# Columns: user_id, movie_id, rating, timestamp\n",
    "data = pd.read_csv('u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Step 0: only select top 50 movies\n",
    "valid_movies = np.array(data['movie_id'].value_counts().index[:50])\n",
    "data = data[data['movie_id'].isin(valid_movies)]\n",
    "\n",
    "# Step 1: Remove users s.t. count >= 2 * unique timestamp\n",
    "temp = data.groupby('user_id')['timestamp'].agg(['count', 'nunique']).reset_index()\n",
    "valid_users = temp[temp['count']/temp['nunique'] < 2]['user_id']\n",
    "data = data[data['user_id'].isin(valid_users)]\n",
    "\n",
    "# Step 2: Deduplicate and recode\n",
    "data = data.groupby(['user_id', 'timestamp'], group_keys=False).apply(lambda group: group.sample(n=1, random_state=42))\n",
    "data = data.sort_values(['user_id', 'timestamp']).reset_index(drop = True)\n",
    "data['movie_id'] = pd.factorize(data['movie_id'])[0] + 1\n",
    "\n",
    "num_users = data['user_id'].nunique()\n",
    "num_movies = data['movie_id'].nunique()\n",
    "num_ratings = len(data)\n",
    "\n",
    "sparsity = 1 - (num_ratings / (num_users * num_movies))\n",
    "\n",
    "print(f\"Filtered Dataset: {num_users} users, {num_movies} movies\")\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e772bc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>874965739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>874965954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13752</th>\n",
       "      <td>943</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>888639407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13753</th>\n",
       "      <td>943</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>888639427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>943</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>888692413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13755</th>\n",
       "      <td>943</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>888692699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>943</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>888693184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  timestamp\n",
       "0            1         1       5  874965478\n",
       "1            1         2       5  874965706\n",
       "2            1         3       5  874965739\n",
       "3            1         4       5  874965758\n",
       "4            1         5       5  874965954\n",
       "...        ...       ...     ...        ...\n",
       "13752      943        23       4  888639407\n",
       "13753      943        13       5  888639427\n",
       "13754      943         8       4  888692413\n",
       "13755      943        41       4  888692699\n",
       "13756      943        20       3  888693184\n",
       "\n",
       "[13757 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fb7404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>943</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>875409939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>943</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>875409978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13730</th>\n",
       "      <td>943</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>875410099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13731</th>\n",
       "      <td>943</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>875501725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13732</th>\n",
       "      <td>943</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>875501774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13733</th>\n",
       "      <td>943</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>875501835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13734</th>\n",
       "      <td>943</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>875501937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>943</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>875501960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13736</th>\n",
       "      <td>943</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>875502042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13737</th>\n",
       "      <td>943</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875502096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13738</th>\n",
       "      <td>943</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>888638897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13739</th>\n",
       "      <td>943</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>888638920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13740</th>\n",
       "      <td>943</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>888638940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13741</th>\n",
       "      <td>943</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>888638960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13742</th>\n",
       "      <td>943</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>888638980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13743</th>\n",
       "      <td>943</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>888639019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13744</th>\n",
       "      <td>943</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>888639042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13745</th>\n",
       "      <td>943</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>888639093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>943</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>888639117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>943</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>888639147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>943</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>888639170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13749</th>\n",
       "      <td>943</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>888639231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>943</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>888639269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>943</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>888639327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13752</th>\n",
       "      <td>943</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>888639407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13753</th>\n",
       "      <td>943</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>888639427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>943</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>888692413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13755</th>\n",
       "      <td>943</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>888692699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>943</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>888693184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  timestamp\n",
       "13728      943        14       5  875409939\n",
       "13729      943        12       4  875409978\n",
       "13730      943        19       4  875410099\n",
       "13731      943        40       5  875501725\n",
       "13732      943         2       5  875501774\n",
       "13733      943         5       4  875501835\n",
       "13734      943        46       4  875501937\n",
       "13735      943        27       3  875501960\n",
       "13736      943        39       4  875502042\n",
       "13737      943        10       3  875502096\n",
       "13738      943        43       2  888638897\n",
       "13739      943        17       4  888638920\n",
       "13740      943         1       4  888638940\n",
       "13741      943        25       5  888638960\n",
       "13742      943        45       5  888638980\n",
       "13743      943        18       5  888639019\n",
       "13744      943        47       4  888639042\n",
       "13745      943        48       3  888639093\n",
       "13746      943        16       3  888639117\n",
       "13747      943        26       4  888639147\n",
       "13748      943        15       2  888639170\n",
       "13749      943        44       3  888639231\n",
       "13750      943        49       5  888639269\n",
       "13751      943        22       4  888639327\n",
       "13752      943        23       4  888639407\n",
       "13753      943        13       5  888639427\n",
       "13754      943         8       4  888692413\n",
       "13755      943        41       4  888692699\n",
       "13756      943        20       3  888693184"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['user_id'] == 943]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb58a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "all_users = data['user_id'].unique()\n",
    "shuffled_indices = np.random.permutation(len(all_users))\n",
    "\n",
    "midpoint = (3 * len(all_users)) // 4\n",
    "indices_1 = shuffled_indices[:midpoint]\n",
    "indices_2 = shuffled_indices[midpoint:]\n",
    "\n",
    "train_users = shuffled_indices[indices_1]\n",
    "test_users = shuffled_indices[indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677beb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['user_id'].isin(train_users)].reset_index(drop = True)\n",
    "data_test = data[data['user_id'].isin(test_users)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7351bbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare baskets\n",
    "def prepare_baskets(data):\n",
    "    return data.groupby(\"user_id\")[\"movie_id\"].apply(list).tolist()\n",
    "\n",
    "train_baskets = prepare_baskets(data_train)\n",
    "test_baskets = prepare_baskets(data_test)\n",
    "\n",
    "train_baskets, val_baskets = train_test_split(train_baskets, test_size=0.25, random_state=42)\n",
    "\n",
    "max_len = max(len(basket) for basket in train_baskets + val_baskets + test_baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a3f422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D = 32\n",
    "batch_size = 256\n",
    "max_epochs = 2000\n",
    "lr = 1e-4\n",
    "max_items = len(set(data_test['movie_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16f4843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_test['movie_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a36bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_baskets(baskets):\n",
    "    context_inputs = []\n",
    "    target_inputs = []\n",
    "    \n",
    "    for basket in baskets:\n",
    "        for idx, elt in enumerate(basket):\n",
    "            target_inputs.append(elt)\n",
    "            context_inputs.append(basket[:idx] + basket[(idx+1):])\n",
    "    \n",
    "    context_inputs = pad_sequences(context_inputs, padding='post', maxlen = max_len - 1, value=0)\n",
    "    return np.array(context_inputs), np.array(target_inputs) - 1\n",
    "\n",
    "train_context_input, train_target_input = preprocess_baskets(train_baskets)\n",
    "val_context_input, val_target_input = preprocess_baskets(val_baskets)\n",
    "test_context_input, test_target_input = preprocess_baskets(test_baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf45303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37,  2,  5, 49, 21, 18,  6, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5831c31c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.9154 - val_loss: 3.9131\n",
      "Epoch 2/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9097 - val_loss: 3.9085\n",
      "Epoch 3/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9059 - val_loss: 3.9045\n",
      "Epoch 4/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8990 - val_loss: 3.9008\n",
      "Epoch 5/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8959 - val_loss: 3.8972\n",
      "Epoch 6/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8907 - val_loss: 3.8938\n",
      "Epoch 7/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8876 - val_loss: 3.8904\n",
      "Epoch 8/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8850 - val_loss: 3.8873\n",
      "Epoch 9/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8820 - val_loss: 3.8840\n",
      "Epoch 10/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8778 - val_loss: 3.8810\n",
      "Epoch 11/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8725 - val_loss: 3.8778\n",
      "Epoch 12/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8684 - val_loss: 3.8747\n",
      "Epoch 13/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8680 - val_loss: 3.8718\n",
      "Epoch 14/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8621 - val_loss: 3.8687\n",
      "Epoch 15/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8597 - val_loss: 3.8657\n",
      "Epoch 16/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8562 - val_loss: 3.8627\n",
      "Epoch 17/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8547 - val_loss: 3.8598\n",
      "Epoch 18/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8498 - val_loss: 3.8568\n",
      "Epoch 19/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8477 - val_loss: 3.8538\n",
      "Epoch 20/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8439 - val_loss: 3.8509\n",
      "Epoch 21/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8425 - val_loss: 3.8480\n",
      "Epoch 22/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8396 - val_loss: 3.8450\n",
      "Epoch 23/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8354 - val_loss: 3.8421\n",
      "Epoch 24/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8332 - val_loss: 3.8391\n",
      "Epoch 25/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8278 - val_loss: 3.8363\n",
      "Epoch 26/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8238 - val_loss: 3.8333\n",
      "Epoch 27/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8186 - val_loss: 3.8303\n",
      "Epoch 28/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8181 - val_loss: 3.8275\n",
      "Epoch 29/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8118 - val_loss: 3.8244\n",
      "Epoch 30/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8127 - val_loss: 3.8215\n",
      "Epoch 31/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8104 - val_loss: 3.8187\n",
      "Epoch 32/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8035 - val_loss: 3.8157\n",
      "Epoch 33/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7989 - val_loss: 3.8129\n",
      "Epoch 34/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7980 - val_loss: 3.8101\n",
      "Epoch 35/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7952 - val_loss: 3.8073\n",
      "Epoch 36/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7895 - val_loss: 3.8043\n",
      "Epoch 37/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7866 - val_loss: 3.8015\n",
      "Epoch 38/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7831 - val_loss: 3.7988\n",
      "Epoch 39/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7817 - val_loss: 3.7959\n",
      "Epoch 40/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7816 - val_loss: 3.7932\n",
      "Epoch 41/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7720 - val_loss: 3.7903\n",
      "Epoch 42/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7725 - val_loss: 3.7875\n",
      "Epoch 43/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7745 - val_loss: 3.7847\n",
      "Epoch 44/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7678 - val_loss: 3.7821\n",
      "Epoch 45/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7574 - val_loss: 3.7794\n",
      "Epoch 46/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7591 - val_loss: 3.7767\n",
      "Epoch 47/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7553 - val_loss: 3.7741\n",
      "Epoch 48/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7498 - val_loss: 3.7713\n",
      "Epoch 49/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7441 - val_loss: 3.7685\n",
      "Epoch 50/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7479 - val_loss: 3.7659\n",
      "Epoch 51/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7463 - val_loss: 3.7632\n",
      "Epoch 52/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7449 - val_loss: 3.7606\n",
      "Epoch 53/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7354 - val_loss: 3.7580\n",
      "Epoch 54/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7318 - val_loss: 3.7554\n",
      "Epoch 55/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7219 - val_loss: 3.7529\n",
      "Epoch 56/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7282 - val_loss: 3.7503\n",
      "Epoch 57/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7213 - val_loss: 3.7479\n",
      "Epoch 58/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7200 - val_loss: 3.7454\n",
      "Epoch 59/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7161 - val_loss: 3.7428\n",
      "Epoch 60/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7146 - val_loss: 3.7403\n",
      "Epoch 61/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7128 - val_loss: 3.7378\n",
      "Epoch 62/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7024 - val_loss: 3.7356\n",
      "Epoch 63/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7012 - val_loss: 3.7329\n",
      "Epoch 64/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6976 - val_loss: 3.7307\n",
      "Epoch 65/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7012 - val_loss: 3.7282\n",
      "Epoch 66/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6945 - val_loss: 3.7257\n",
      "Epoch 67/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6907 - val_loss: 3.7234\n",
      "Epoch 68/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6895 - val_loss: 3.7212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6805 - val_loss: 3.7188\n",
      "Epoch 70/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6807 - val_loss: 3.7166\n",
      "Epoch 71/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6759 - val_loss: 3.7143\n",
      "Epoch 72/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6731 - val_loss: 3.7119\n",
      "Epoch 73/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6725 - val_loss: 3.7097\n",
      "Epoch 74/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6694 - val_loss: 3.7072\n",
      "Epoch 75/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6696 - val_loss: 3.7051\n",
      "Epoch 76/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6587 - val_loss: 3.7026\n",
      "Epoch 77/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6560 - val_loss: 3.7004\n",
      "Epoch 78/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6597 - val_loss: 3.6981\n",
      "Epoch 79/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6524 - val_loss: 3.6958\n",
      "Epoch 80/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6474 - val_loss: 3.6938\n",
      "Epoch 81/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6427 - val_loss: 3.6916\n",
      "Epoch 82/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6419 - val_loss: 3.6894\n",
      "Epoch 83/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6447 - val_loss: 3.6871\n",
      "Epoch 84/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6392 - val_loss: 3.6850\n",
      "Epoch 85/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6304 - val_loss: 3.6827\n",
      "Epoch 86/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6200 - val_loss: 3.6808\n",
      "Epoch 87/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6269 - val_loss: 3.6784\n",
      "Epoch 88/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6270 - val_loss: 3.6764\n",
      "Epoch 89/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6201 - val_loss: 3.6743\n",
      "Epoch 90/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6260 - val_loss: 3.6720\n",
      "Epoch 91/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6153 - val_loss: 3.6700\n",
      "Epoch 92/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6160 - val_loss: 3.6679\n",
      "Epoch 93/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6021 - val_loss: 3.6662\n",
      "Epoch 94/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6172 - val_loss: 3.6638\n",
      "Epoch 95/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6059 - val_loss: 3.6622\n",
      "Epoch 96/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5970 - val_loss: 3.6600\n",
      "Epoch 97/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6013 - val_loss: 3.6578\n",
      "Epoch 98/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5990 - val_loss: 3.6558\n",
      "Epoch 99/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5813 - val_loss: 3.6536\n",
      "Epoch 100/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5915 - val_loss: 3.6516\n",
      "Epoch 101/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5872 - val_loss: 3.6498\n",
      "Epoch 102/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5821 - val_loss: 3.6479\n",
      "Epoch 103/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5775 - val_loss: 3.6457\n",
      "Epoch 104/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5687 - val_loss: 3.6439\n",
      "Epoch 105/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5800 - val_loss: 3.6421\n",
      "Epoch 106/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5672 - val_loss: 3.6401\n",
      "Epoch 107/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5596 - val_loss: 3.6382\n",
      "Epoch 108/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5568 - val_loss: 3.6365\n",
      "Epoch 109/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5643 - val_loss: 3.6344\n",
      "Epoch 110/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5518 - val_loss: 3.6321\n",
      "Epoch 111/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5559 - val_loss: 3.6307\n",
      "Epoch 112/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5505 - val_loss: 3.6286\n",
      "Epoch 113/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5453 - val_loss: 3.6269\n",
      "Epoch 114/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5469 - val_loss: 3.6248\n",
      "Epoch 115/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5281 - val_loss: 3.6233\n",
      "Epoch 116/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5387 - val_loss: 3.6212\n",
      "Epoch 117/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5155 - val_loss: 3.6197\n",
      "Epoch 118/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5322 - val_loss: 3.6181\n",
      "Epoch 119/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5262 - val_loss: 3.6163\n",
      "Epoch 120/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5280 - val_loss: 3.6144\n",
      "Epoch 121/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5124 - val_loss: 3.6127\n",
      "Epoch 122/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5168 - val_loss: 3.6108\n",
      "Epoch 123/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5226 - val_loss: 3.6093\n",
      "Epoch 124/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5118 - val_loss: 3.6075\n",
      "Epoch 125/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5175 - val_loss: 3.6059\n",
      "Epoch 126/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5098 - val_loss: 3.6042\n",
      "Epoch 127/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5024 - val_loss: 3.6025\n",
      "Epoch 128/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5015 - val_loss: 3.6007\n",
      "Epoch 129/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5023 - val_loss: 3.5996\n",
      "Epoch 130/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5024 - val_loss: 3.5977\n",
      "Epoch 131/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4926 - val_loss: 3.5964\n",
      "Epoch 132/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4948 - val_loss: 3.5950\n",
      "Epoch 133/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4857 - val_loss: 3.5934\n",
      "Epoch 134/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4942 - val_loss: 3.5921\n",
      "Epoch 135/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4772 - val_loss: 3.5900\n",
      "Epoch 136/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4893 - val_loss: 3.5888\n",
      "Epoch 137/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4647 - val_loss: 3.5874\n",
      "Epoch 138/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4575 - val_loss: 3.5856\n",
      "Epoch 139/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4721 - val_loss: 3.5843\n",
      "Epoch 140/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4684 - val_loss: 3.5833\n",
      "Epoch 141/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4623 - val_loss: 3.5819\n",
      "Epoch 142/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4625 - val_loss: 3.5806\n",
      "Epoch 143/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4554 - val_loss: 3.5787\n",
      "Epoch 144/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4450 - val_loss: 3.5774\n",
      "Epoch 145/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4445 - val_loss: 3.5757\n",
      "Epoch 146/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4553 - val_loss: 3.5746\n",
      "Epoch 147/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4492 - val_loss: 3.5732\n",
      "Epoch 148/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4362 - val_loss: 3.5717\n",
      "Epoch 149/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4379 - val_loss: 3.5706\n",
      "Epoch 150/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4389 - val_loss: 3.5698\n",
      "Epoch 151/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4352 - val_loss: 3.5678\n",
      "Epoch 152/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4272 - val_loss: 3.5668\n",
      "Epoch 153/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4247 - val_loss: 3.5650\n",
      "Epoch 154/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4219 - val_loss: 3.5643\n",
      "Epoch 155/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4226 - val_loss: 3.5629\n",
      "Epoch 156/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4164 - val_loss: 3.5620\n",
      "Epoch 157/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4135 - val_loss: 3.5607\n",
      "Epoch 158/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4114 - val_loss: 3.5594\n",
      "Epoch 159/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4081 - val_loss: 3.5585\n",
      "Epoch 160/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3980 - val_loss: 3.5570\n",
      "Epoch 161/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4017 - val_loss: 3.5563\n",
      "Epoch 162/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4024 - val_loss: 3.5554\n",
      "Epoch 163/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4094 - val_loss: 3.5542\n",
      "Epoch 164/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3934 - val_loss: 3.5526\n",
      "Epoch 165/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3878 - val_loss: 3.5520\n",
      "Epoch 166/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4036 - val_loss: 3.5505\n",
      "Epoch 167/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3926 - val_loss: 3.5496\n",
      "Epoch 168/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3647 - val_loss: 3.5490\n",
      "Epoch 169/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3873 - val_loss: 3.5477\n",
      "Epoch 170/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3786 - val_loss: 3.5468\n",
      "Epoch 171/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3650 - val_loss: 3.5463\n",
      "Epoch 172/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3762 - val_loss: 3.5445\n",
      "Epoch 173/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3816 - val_loss: 3.5439\n",
      "Epoch 174/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3726 - val_loss: 3.5431\n",
      "Epoch 175/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3631 - val_loss: 3.5423\n",
      "Epoch 176/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3725 - val_loss: 3.5417\n",
      "Epoch 177/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3676 - val_loss: 3.5403\n",
      "Epoch 178/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3609 - val_loss: 3.5397\n",
      "Epoch 179/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3576 - val_loss: 3.5389\n",
      "Epoch 180/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3479 - val_loss: 3.5379\n",
      "Epoch 181/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3460 - val_loss: 3.5369\n",
      "Epoch 182/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3591 - val_loss: 3.5365\n",
      "Epoch 183/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3353 - val_loss: 3.5357\n",
      "Epoch 184/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3535 - val_loss: 3.5348\n",
      "Epoch 185/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3367 - val_loss: 3.5341\n",
      "Epoch 186/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3406 - val_loss: 3.5336\n",
      "Epoch 187/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3322 - val_loss: 3.5324\n",
      "Epoch 188/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3303 - val_loss: 3.5321\n",
      "Epoch 189/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3159 - val_loss: 3.5316\n",
      "Epoch 190/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3269 - val_loss: 3.5307\n",
      "Epoch 191/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3248 - val_loss: 3.5301\n",
      "Epoch 192/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3174 - val_loss: 3.5290\n",
      "Epoch 193/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3087 - val_loss: 3.5282\n",
      "Epoch 194/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3225 - val_loss: 3.5275\n",
      "Epoch 195/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3071 - val_loss: 3.5266\n",
      "Epoch 196/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3183 - val_loss: 3.5265\n",
      "Epoch 197/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3217 - val_loss: 3.5261\n",
      "Epoch 198/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3066 - val_loss: 3.5255\n",
      "Epoch 199/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3074 - val_loss: 3.5245\n",
      "Epoch 200/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3058 - val_loss: 3.5244\n",
      "Epoch 201/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3030 - val_loss: 3.5242\n",
      "Epoch 202/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2856 - val_loss: 3.5229\n",
      "Epoch 203/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3022 - val_loss: 3.5224\n",
      "Epoch 204/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2891 - val_loss: 3.5223\n",
      "Epoch 205/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2916 - val_loss: 3.5218\n",
      "Epoch 206/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2904 - val_loss: 3.5214\n",
      "Epoch 207/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2722 - val_loss: 3.5212\n",
      "Epoch 208/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2896 - val_loss: 3.5207\n",
      "Epoch 209/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2787 - val_loss: 3.5205\n",
      "Epoch 210/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2864 - val_loss: 3.5202\n",
      "Epoch 211/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2907 - val_loss: 3.5194\n",
      "Epoch 212/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2753 - val_loss: 3.5187\n",
      "Epoch 213/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2661 - val_loss: 3.5183\n",
      "Epoch 214/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2773 - val_loss: 3.5176\n",
      "Epoch 215/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2633 - val_loss: 3.5176\n",
      "Epoch 216/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2758 - val_loss: 3.5170\n",
      "Epoch 217/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2727 - val_loss: 3.5166\n",
      "Epoch 218/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2577 - val_loss: 3.5164\n",
      "Epoch 219/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2548 - val_loss: 3.5157\n",
      "Epoch 220/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2489 - val_loss: 3.5156\n",
      "Epoch 221/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2403 - val_loss: 3.5154\n",
      "Epoch 222/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2466 - val_loss: 3.5148\n",
      "Epoch 223/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2590 - val_loss: 3.5150\n",
      "Epoch 224/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2458 - val_loss: 3.5143\n",
      "Epoch 225/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2381 - val_loss: 3.5142\n",
      "Epoch 226/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2412 - val_loss: 3.5138\n",
      "Epoch 227/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2339 - val_loss: 3.5133\n",
      "Epoch 228/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2274 - val_loss: 3.5128\n",
      "Epoch 229/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2397 - val_loss: 3.5131\n",
      "Epoch 230/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2370 - val_loss: 3.5130\n",
      "Epoch 231/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2260 - val_loss: 3.5122\n",
      "Epoch 232/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2255 - val_loss: 3.5122\n",
      "Epoch 233/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2101 - val_loss: 3.5125\n",
      "Epoch 234/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2255 - val_loss: 3.5122\n",
      "Epoch 235/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2302 - val_loss: 3.5121\n",
      "Epoch 236/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2211 - val_loss: 3.5116\n",
      "Epoch 237/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2245 - val_loss: 3.5112\n",
      "Epoch 238/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2246 - val_loss: 3.5115\n",
      "Epoch 239/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2117 - val_loss: 3.5115\n",
      "Epoch 240/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2110 - val_loss: 3.5112\n",
      "Epoch 241/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2201 - val_loss: 3.5113\n",
      "Epoch 242/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1985 - val_loss: 3.5115\n",
      "Epoch 243/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1979 - val_loss: 3.5113\n",
      "Epoch 244/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1959 - val_loss: 3.5111\n",
      "Epoch 245/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1976 - val_loss: 3.5107\n",
      "Epoch 246/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1954 - val_loss: 3.5105\n",
      "Epoch 247/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2046 - val_loss: 3.5112\n",
      "Epoch 248/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1994 - val_loss: 3.5115\n",
      "Epoch 249/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1909 - val_loss: 3.5108\n",
      "Epoch 250/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1978 - val_loss: 3.5107\n",
      "Epoch 251/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1744 - val_loss: 3.5107\n",
      "Epoch 252/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1689 - val_loss: 3.5100\n",
      "Epoch 253/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1824 - val_loss: 3.5108\n",
      "Epoch 254/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1892 - val_loss: 3.5107\n",
      "Epoch 255/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1771 - val_loss: 3.5101\n",
      "Epoch 256/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1784 - val_loss: 3.5106\n",
      "Epoch 257/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1632 - val_loss: 3.5108\n",
      "Epoch 258/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1876 - val_loss: 3.5107\n",
      "Epoch 259/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1646 - val_loss: 3.5108\n",
      "Epoch 260/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1654 - val_loss: 3.5107\n",
      "Epoch 261/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1580 - val_loss: 3.5105\n",
      "Epoch 262/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1872 - val_loss: 3.5109\n"
     ]
    }
   ],
   "source": [
    "input_context = layers.Input(shape=(max_len - 1,), dtype=tf.int32, name=\"context_input\")\n",
    "\n",
    "alpha_embedding = layers.Embedding(input_dim=max_items + 1, output_dim=D, name=\"alpha_embedding\")\n",
    "context_embedding = alpha_embedding(input_context)  # Shape: (batch_size, max_len, embedding_dim)\n",
    "\n",
    "class ZeroMaskEmbedding(layers.Layer):\n",
    "    def call(self, embeddings, input_tokens):\n",
    "        mask = tf.cast(tf.not_equal(input_tokens, 0), tf.float32) \n",
    "        mask = tf.expand_dims(mask, axis=-1) \n",
    "        return embeddings * mask \n",
    "\n",
    "context_embedding = ZeroMaskEmbedding()(context_embedding, input_context)\n",
    "\n",
    "class SumLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.reduce_sum(inputs, axis=1) \n",
    "\n",
    "summed_context = SumLayer()(context_embedding)\n",
    "\n",
    "output = layers.Dense(max_items, activation=\"softmax\", name=\"output_layer\", use_bias = False)(summed_context)\n",
    "\n",
    "model = Model(inputs=input_context, outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_context_input, train_target_input,        \n",
    "    validation_data=(val_context_input, val_target_input),\n",
    "    batch_size=batch_size,\n",
    "    epochs=max_epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76564c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ alpha_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │ context_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ zero_mask_embedding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ alpha_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroMaskEmbedding</span>) │                   │            │ context_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sum_layer           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ zero_mask_embedd… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SumLayer</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ sum_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ alpha_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,632\u001b[0m │ context_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ zero_mask_embedding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ alpha_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mZeroMaskEmbedding\u001b[0m) │                   │            │ context_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sum_layer           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ zero_mask_embedd… │\n",
       "│ (\u001b[38;5;33mSumLayer\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m1,600\u001b[0m │ sum_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,698</span> (37.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,698\u001b[0m (37.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> (12.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,232\u001b[0m (12.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,466</span> (25.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,466\u001b[0m (25.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77910046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5181 \n",
      "Test Loss: 3.5656931400299072\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Test Data\n",
    "test_loss = model.evaluate(test_context_input, test_target_input, batch_size=batch_size)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
