{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soRlv0CAkPhK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BidhgCekpBE"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('city_temperature.csv', low_memory = False)\n",
    "data = data[(data['Country'] == 'US')]\n",
    "data = data[['State', 'City', 'Month', 'Day', 'Year', 'AvgTemperature']]\n",
    "data = data[((data['Month'] == 10) | ((data['Month'] == 9) & (data['Day'] == 30))) & (data['Year'] >= 2007)]\n",
    "data = data[~data['State'].isin(['Alaska', 'Hawaii', 'Additional Territories', 'District of Columbia'])].reset_index(drop = True)\n",
    "\n",
    "### Train: 2007-2012 (6 yrs)\n",
    "### Validation: 2013-2016 (4 yrs)\n",
    "### Test: 2017-2019 (3 yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1m9VtXS5k1fU"
   },
   "outputs": [],
   "source": [
    "lat_lon = pd.read_csv('all_cities_lat_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRxhy-pAk2v2"
   },
   "outputs": [],
   "source": [
    "final = data.drop_duplicates().merge(lat_lon, on = ['State', 'City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "Ue_YJJh_k3oU",
    "outputId": "fd058e67-3fe8-4fc5-b4c0-8f8b2b7b1d49"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"final[final['AvgTemperature'] == -99]\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Arizona\",\n          \"Connecticut\",\n          \"South Dakota\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Phoenix\",\n          \"Bridgeport\",\n          \"Rapid City\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 10,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 1,\n        \"max\": 18,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2010,\n        \"max\": 2016,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2010\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AvgTemperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -99.0,\n        \"max\": -99.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -99.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.6661023213772985,\n        \"min\": 33.448376,\n        \"max\": 44.080544,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          33.448376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.6425085125396,\n        \"min\": -112.074036,\n        \"max\": -73.195557,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -112.074036\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d57875f2-75c7-4a14-aacc-6fb3b1b16238\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>AvgTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>33.448376</td>\n",
       "      <td>-112.074036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>33.448376</td>\n",
       "      <td>-112.074036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>33.448376</td>\n",
       "      <td>-112.074036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>33.448376</td>\n",
       "      <td>-112.074036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>33.448376</td>\n",
       "      <td>-112.074036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>41.186390</td>\n",
       "      <td>-73.195557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>41.186390</td>\n",
       "      <td>-73.195557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>41.186390</td>\n",
       "      <td>-73.195557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2016</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>41.186390</td>\n",
       "      <td>-73.195557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Rapid City</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>44.080544</td>\n",
       "      <td>-103.231018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Rapid City</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>44.080544</td>\n",
       "      <td>-103.231018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d57875f2-75c7-4a14-aacc-6fb3b1b16238')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d57875f2-75c7-4a14-aacc-6fb3b1b16238 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d57875f2-75c7-4a14-aacc-6fb3b1b16238');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-cfb20324-c5eb-4720-8dd1-aaabe455d86f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfb20324-c5eb-4720-8dd1-aaabe455d86f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-cfb20324-c5eb-4720-8dd1-aaabe455d86f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              State        City  Month  Day  Year  AvgTemperature   Latitude  \\\n",
       "513         Arizona     Phoenix     10    1  2010           -99.0  33.448376   \n",
       "514         Arizona     Phoenix     10    2  2010           -99.0  33.448376   \n",
       "545         Arizona     Phoenix     10    1  2011           -99.0  33.448376   \n",
       "577         Arizona     Phoenix     10    1  2012           -99.0  33.448376   \n",
       "673         Arizona     Phoenix     10    1  2015           -99.0  33.448376   \n",
       "2383    Connecticut  Bridgeport     10   15  2016           -99.0  41.186390   \n",
       "2384    Connecticut  Bridgeport     10   16  2016           -99.0  41.186390   \n",
       "2385    Connecticut  Bridgeport     10   17  2016           -99.0  41.186390   \n",
       "2386    Connecticut  Bridgeport     10   18  2016           -99.0  41.186390   \n",
       "15589  South Dakota  Rapid City     10    5  2013           -99.0  44.080544   \n",
       "15590  South Dakota  Rapid City     10    6  2013           -99.0  44.080544   \n",
       "\n",
       "        Longitude  \n",
       "513   -112.074036  \n",
       "514   -112.074036  \n",
       "545   -112.074036  \n",
       "577   -112.074036  \n",
       "673   -112.074036  \n",
       "2383   -73.195557  \n",
       "2384   -73.195557  \n",
       "2385   -73.195557  \n",
       "2386   -73.195557  \n",
       "15589 -103.231018  \n",
       "15590 -103.231018  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['AvgTemperature'] == -99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bz_b7FZVk4aW"
   },
   "outputs": [],
   "source": [
    "final = final[~final['State'].isin(['Arizona', 'Connecticut', 'South Dakota'])].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0T9v6fG6k5Xi"
   },
   "outputs": [],
   "source": [
    "### Convert the masked temperature to ZERO\n",
    "\n",
    "def generate_data(year_min, year_max):\n",
    "\n",
    "    masked_temps = []\n",
    "    masked_bools = []\n",
    "    masked_idxs = []\n",
    "    lag_inds = []\n",
    "    coords = []\n",
    "    target_temps = []\n",
    "\n",
    "    for year in range(year_min, year_max + 1):\n",
    "        for day in range(1, 32):\n",
    "\n",
    "            temp = final[(final['Day'] == day) & (final['Month'] == 10) & (final['Year'] == year)].reset_index(drop = True)\n",
    "            nrow = temp.shape[0]\n",
    "\n",
    "            if day == 1:\n",
    "                temp2 = final[(final['Day'] == 30) & (final['Month'] == 9) & (final['Year'] == year)].reset_index(drop = True)\n",
    "            else:\n",
    "                temp2 = final[(final['Day'] == day - 1) & (final['Month'] == 10) & (final['Year'] == year)].reset_index(drop = True)\n",
    "\n",
    "            for i in range(nrow):\n",
    "                masked_temp = list(temp['AvgTemperature'])\n",
    "                target_temps.append(masked_temp[i])\n",
    "                masked_temp[i] = 0\n",
    "                masked_temp += list(temp2['AvgTemperature'])\n",
    "                masked_temps.append(masked_temp)\n",
    "                masked_idxs.append(i)\n",
    "                masked_bool = [0] * (2 * nrow)\n",
    "                masked_bool[i] = 1\n",
    "                masked_bools.append(masked_bool)\n",
    "                lag_ind = [0] * nrow + [1] * nrow\n",
    "                lag_inds.append(lag_ind)\n",
    "                coords.append(np.tile(np.array(temp[['Latitude', 'Longitude']]), (2, 1)))\n",
    "\n",
    "\n",
    "    return np.array(masked_temps), np.array(masked_bools), np.array(masked_idxs), \\\n",
    "        np.array(lag_inds), np.array(coords), np.array(target_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdyNV0fek6IP"
   },
   "outputs": [],
   "source": [
    "train_masked_temps, train_masked_bools, train_masked_idxs, train_lag_inds, train_coords, train_target_temps = \\\n",
    "    generate_data(2007, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DqBCFaFk7MO"
   },
   "outputs": [],
   "source": [
    "val_masked_temps, val_masked_bools, val_masked_idxs, val_lag_inds, val_coords, val_target_temps = \\\n",
    "    generate_data(2013, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3eaIdGnk-yF"
   },
   "outputs": [],
   "source": [
    "test_masked_temps, test_masked_bools, test_masked_idxs, test_lag_inds, test_coords, test_target_temps = \\\n",
    "    generate_data(2017, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfSiCQHMlMpL",
    "outputId": "7f3cea48-0c16-461b-cea3-dbf15e312b33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4092, 88)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lag_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z83vLiEmlA0V",
    "outputId": "93626ec2-a224-47a4-cc00-f72286318d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - loss: 2722.6147 - val_loss: 823.7673\n",
      "Epoch 2/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 30ms/step - loss: 326.3911 - val_loss: 99.8120\n",
      "Epoch 3/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 101.2029 - val_loss: 55.6138\n",
      "Epoch 4/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 58.6472 - val_loss: 46.1459\n",
      "Epoch 5/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 41.5299 - val_loss: 36.7678\n",
      "Epoch 6/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 39.3908 - val_loss: 28.9146\n",
      "Epoch 7/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 34.8230 - val_loss: 28.5028\n",
      "Epoch 8/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 32.0425 - val_loss: 24.2700\n",
      "Epoch 9/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 27.9893 - val_loss: 23.1286\n",
      "Epoch 10/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 26.3197 - val_loss: 21.2760\n",
      "Epoch 11/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 24.0346 - val_loss: 20.4391\n",
      "Epoch 12/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 23.5958 - val_loss: 24.8193\n",
      "Epoch 13/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 22.3561 - val_loss: 31.5142\n",
      "Epoch 14/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 26.5132 - val_loss: 17.1724\n",
      "Epoch 15/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 18.9053 - val_loss: 19.3755\n",
      "Epoch 16/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 18.9095 - val_loss: 17.4495\n",
      "Epoch 17/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 18.3744 - val_loss: 16.6648\n",
      "Epoch 18/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 17.9518 - val_loss: 19.1523\n",
      "Epoch 19/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 17.6611 - val_loss: 15.5112\n",
      "Epoch 20/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 15.7839 - val_loss: 16.8965\n",
      "Epoch 21/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 18.4662 - val_loss: 18.3844\n",
      "Epoch 22/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 16.7888 - val_loss: 15.0878\n",
      "Epoch 23/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 15.6797 - val_loss: 14.8926\n",
      "Epoch 24/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 14.7718 - val_loss: 13.8748\n",
      "Epoch 25/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 14.8867 - val_loss: 12.8847\n",
      "Epoch 26/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 13.2352 - val_loss: 14.5495\n",
      "Epoch 27/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 13.0011 - val_loss: 12.8386\n",
      "Epoch 28/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 15.9083 - val_loss: 13.8036\n",
      "Epoch 29/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 13.4683 - val_loss: 14.2699\n",
      "Epoch 30/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 13.4979 - val_loss: 11.9096\n",
      "Epoch 31/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 12.6222 - val_loss: 13.5279\n",
      "Epoch 32/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 12.8615 - val_loss: 11.2998\n",
      "Epoch 33/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 11.1349 - val_loss: 12.3406\n",
      "Epoch 34/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 13.6482 - val_loss: 11.1204\n",
      "Epoch 35/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 12.0837 - val_loss: 11.0015\n",
      "Epoch 36/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 11.0632 - val_loss: 10.3561\n",
      "Epoch 37/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 10.6753 - val_loss: 10.5642\n",
      "Epoch 38/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 10.1511 - val_loss: 9.5716\n",
      "Epoch 39/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 10.3629 - val_loss: 13.4454\n",
      "Epoch 40/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 11.2738 - val_loss: 9.7078\n",
      "Epoch 41/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 9.6105 - val_loss: 10.0966\n",
      "Epoch 42/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 9.9876 - val_loss: 13.0563\n",
      "Epoch 43/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 9.9957 - val_loss: 10.7931\n",
      "Epoch 44/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 9.8500 - val_loss: 11.5052\n",
      "Epoch 45/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 10.5082 - val_loss: 10.5120\n",
      "Epoch 46/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 9.5942 - val_loss: 11.3687\n",
      "Epoch 47/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 9.4605 - val_loss: 9.5458\n",
      "Epoch 48/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 9.4733 - val_loss: 9.6056\n",
      "Epoch 49/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 8.7940 - val_loss: 9.2845\n",
      "Epoch 50/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 9.0910 - val_loss: 11.3157\n",
      "Epoch 51/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 9.2227 - val_loss: 13.1030\n",
      "Epoch 52/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 9.6292 - val_loss: 11.2956\n",
      "Epoch 53/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 10.0394 - val_loss: 9.4589\n",
      "Epoch 54/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 8.6777 - val_loss: 8.5068\n",
      "Epoch 55/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 8.3792 - val_loss: 8.5893\n",
      "Epoch 56/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 8.3466 - val_loss: 8.5386\n",
      "Epoch 57/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 8.1776 - val_loss: 9.2998\n",
      "Epoch 58/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 8.5914 - val_loss: 9.1161\n",
      "Epoch 59/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 9.3800 - val_loss: 9.0728\n",
      "Epoch 60/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 8.1865 - val_loss: 11.5091\n",
      "Epoch 61/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 9.2629 - val_loss: 9.7323\n",
      "Epoch 62/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 8.5284 - val_loss: 9.1588\n",
      "Epoch 63/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 8.1507 - val_loss: 8.8269\n",
      "Epoch 64/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 8.3775 - val_loss: 8.9007\n",
      "Epoch 65/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 8.0232 - val_loss: 8.9760\n",
      "Epoch 66/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 7.9225 - val_loss: 8.7603\n",
      "Epoch 67/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 8.2411 - val_loss: 11.3972\n",
      "Epoch 68/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 9.3243 - val_loss: 8.1814\n",
      "Epoch 69/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 8.0331 - val_loss: 8.3041\n",
      "Epoch 70/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 7.0523 - val_loss: 8.4142\n",
      "Epoch 71/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 7.7227 - val_loss: 8.1350\n",
      "Epoch 72/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.4757 - val_loss: 10.0692\n",
      "Epoch 73/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 7.7659 - val_loss: 7.7659\n",
      "Epoch 74/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.8016 - val_loss: 8.2017\n",
      "Epoch 75/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 7.1730 - val_loss: 7.8408\n",
      "Epoch 76/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 8.0900 - val_loss: 9.6391\n",
      "Epoch 77/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 7.7447 - val_loss: 8.6317\n",
      "Epoch 78/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 7.5152 - val_loss: 7.9705\n",
      "Epoch 79/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 6.9819 - val_loss: 8.4605\n",
      "Epoch 80/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 7.6302 - val_loss: 8.2387\n",
      "Epoch 81/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 7.3472 - val_loss: 8.1556\n",
      "Epoch 82/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 7.5811 - val_loss: 9.0152\n",
      "Epoch 83/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.5792 - val_loss: 8.0215\n",
      "Epoch 84/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 6.7104 - val_loss: 8.1644\n",
      "Epoch 85/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.8981 - val_loss: 8.4446\n",
      "Epoch 86/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 6.7997 - val_loss: 8.3591\n",
      "Epoch 87/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 7.9183 - val_loss: 9.2446\n",
      "Epoch 88/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 7.2368 - val_loss: 8.0623\n",
      "Epoch 89/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.9159 - val_loss: 10.5240\n",
      "Epoch 90/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 8.0037 - val_loss: 8.3171\n",
      "Epoch 91/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.2629 - val_loss: 7.7139\n",
      "Epoch 92/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 6.6370 - val_loss: 8.7975\n",
      "Epoch 93/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 6.9521 - val_loss: 8.3540\n",
      "Epoch 94/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 7.7432 - val_loss: 7.3752\n",
      "Epoch 95/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 6.9535 - val_loss: 9.7289\n",
      "Epoch 96/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 7.1285 - val_loss: 7.2718\n",
      "Epoch 97/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 7.4930 - val_loss: 9.6921\n",
      "Epoch 98/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 7.5679 - val_loss: 7.8006\n",
      "Epoch 99/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 7.2593 - val_loss: 10.7514\n",
      "Epoch 100/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 7.4621 - val_loss: 7.5859\n",
      "Epoch 101/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.6401 - val_loss: 8.2121\n",
      "Epoch 102/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 6.7150 - val_loss: 8.7587\n",
      "Epoch 103/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.2933 - val_loss: 8.1282\n",
      "Epoch 104/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 6.9188 - val_loss: 8.4342\n",
      "Epoch 105/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 6.9697 - val_loss: 7.6490\n",
      "Epoch 106/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 6.4783 - val_loss: 8.1529\n",
      "Epoch 107/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 6.8034 - val_loss: 9.0509\n",
      "Epoch 108/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 7.1592 - val_loss: 8.8864\n",
      "Epoch 109/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 7.4207 - val_loss: 8.9783\n",
      "Epoch 110/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 7.1441 - val_loss: 7.5932\n",
      "Epoch 111/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.9847 - val_loss: 8.5482\n",
      "Epoch 112/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 6.8031 - val_loss: 7.6776\n",
      "Epoch 113/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 6.6473 - val_loss: 9.3002\n",
      "Epoch 114/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 7.7180 - val_loss: 8.1634\n",
      "Epoch 115/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 7.1703 - val_loss: 7.8730\n",
      "Epoch 116/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.2531 - val_loss: 8.3579\n",
      "Epoch 117/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 6.3922 - val_loss: 7.8339\n",
      "Epoch 118/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 6.3608 - val_loss: 7.8087\n",
      "Epoch 119/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.9702 - val_loss: 7.4115\n",
      "Epoch 120/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 7.1675 - val_loss: 7.7791\n",
      "Epoch 121/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 6.3168 - val_loss: 10.0568\n",
      "Epoch 122/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 6.9107 - val_loss: 7.8382\n",
      "Epoch 123/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 6.3767 - val_loss: 7.4601\n",
      "Epoch 124/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.4111 - val_loss: 8.1201\n",
      "Epoch 125/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5.9675 - val_loss: 7.2944\n",
      "Epoch 126/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.8279 - val_loss: 9.1992\n",
      "Epoch 127/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 6.4696 - val_loss: 8.2443\n",
      "Epoch 128/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 6.3891 - val_loss: 7.6014\n",
      "Epoch 129/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 6.0671 - val_loss: 7.5317\n",
      "Epoch 130/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 6.2699 - val_loss: 7.4380\n",
      "Epoch 131/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 6.3390 - val_loss: 7.1586\n",
      "Epoch 132/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.4737 - val_loss: 7.8129\n",
      "Epoch 133/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 6.3601 - val_loss: 8.7673\n",
      "Epoch 134/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.9715 - val_loss: 8.4855\n",
      "Epoch 135/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.0612 - val_loss: 8.6947\n",
      "Epoch 136/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 6.5531 - val_loss: 10.1888\n",
      "Epoch 137/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 6.5301 - val_loss: 7.1177\n",
      "Epoch 138/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.9290 - val_loss: 7.9706\n",
      "Epoch 139/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 6.9281 - val_loss: 8.2503\n",
      "Epoch 140/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 6.1275 - val_loss: 7.5875\n",
      "Epoch 141/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.0614 - val_loss: 7.9376\n",
      "Epoch 142/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 6.0597 - val_loss: 8.3754\n",
      "Epoch 143/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 6.0196 - val_loss: 8.7448\n",
      "Epoch 144/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 6.7292 - val_loss: 7.6505\n",
      "Epoch 145/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.6599 - val_loss: 9.0820\n",
      "Epoch 146/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.2551 - val_loss: 7.2438\n",
      "Epoch 147/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 5.5249 - val_loss: 7.8523\n",
      "Epoch 148/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.9900 - val_loss: 7.8199\n",
      "Epoch 149/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.5926 - val_loss: 7.4769\n",
      "Epoch 150/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.0954 - val_loss: 10.6293\n",
      "Epoch 151/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 7.4036 - val_loss: 9.3835\n",
      "Epoch 152/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 6.9035 - val_loss: 7.6736\n",
      "Epoch 153/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 6.0625 - val_loss: 7.7470\n",
      "Epoch 154/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.8077 - val_loss: 8.5040\n",
      "Epoch 155/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5.9644 - val_loss: 7.4464\n",
      "Epoch 156/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 5.8770 - val_loss: 9.2177\n",
      "Epoch 157/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 6.8439 - val_loss: 7.7106\n",
      "Epoch 158/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 5.6667 - val_loss: 8.7148\n",
      "Epoch 159/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 6.0094 - val_loss: 7.7209\n",
      "Epoch 160/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.8221 - val_loss: 7.6989\n",
      "Epoch 161/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.5596 - val_loss: 7.5051\n",
      "Epoch 162/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.5857 - val_loss: 7.9834\n",
      "Epoch 163/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 5.9451 - val_loss: 7.3053\n",
      "Epoch 164/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 5.4961 - val_loss: 9.1221\n",
      "Epoch 165/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 6.4464 - val_loss: 7.5957\n",
      "Epoch 166/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.5688 - val_loss: 7.2492\n",
      "Epoch 167/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.1220 - val_loss: 8.3990\n",
      "Epoch 168/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.8673 - val_loss: 7.5306\n",
      "Epoch 169/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.4231 - val_loss: 8.6822\n",
      "Epoch 170/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 6.0219 - val_loss: 7.8670\n",
      "Epoch 171/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.4589 - val_loss: 9.1757\n",
      "Epoch 172/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 6.2246 - val_loss: 8.5523\n",
      "Epoch 173/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.7484 - val_loss: 8.0471\n",
      "Epoch 174/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.9304 - val_loss: 8.0331\n",
      "Epoch 175/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 6.0757 - val_loss: 7.5250\n",
      "Epoch 176/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 5.5467 - val_loss: 7.4879\n",
      "Epoch 177/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.9141 - val_loss: 7.6965\n",
      "Epoch 178/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.5844 - val_loss: 7.6435\n",
      "Epoch 179/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.3090 - val_loss: 7.9771\n",
      "Epoch 180/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.7975 - val_loss: 7.2450\n",
      "Epoch 181/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 5.2820 - val_loss: 7.1198\n",
      "Epoch 182/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.5291 - val_loss: 7.5829\n",
      "Epoch 183/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.0542 - val_loss: 7.4968\n",
      "Epoch 184/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.3065 - val_loss: 9.4166\n",
      "Epoch 185/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.7640 - val_loss: 7.5575\n",
      "Epoch 186/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.3254 - val_loss: 7.9013\n",
      "Epoch 187/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 5.3338 - val_loss: 7.4842\n",
      "Epoch 188/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.9736 - val_loss: 7.8834\n",
      "Epoch 189/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.1202 - val_loss: 7.4981\n",
      "Epoch 190/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.0809 - val_loss: 8.0831\n",
      "Epoch 191/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.5474 - val_loss: 8.5157\n",
      "Epoch 192/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.9143 - val_loss: 8.2624\n",
      "Epoch 193/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 6.1823 - val_loss: 8.1713\n",
      "Epoch 194/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5.7707 - val_loss: 7.3111\n",
      "Epoch 195/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.1601 - val_loss: 7.5291\n",
      "Epoch 196/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 5.2036 - val_loss: 10.0521\n",
      "Epoch 197/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.3817 - val_loss: 7.9320\n",
      "Epoch 198/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 5.4180 - val_loss: 7.7867\n",
      "Epoch 199/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 5.5826 - val_loss: 9.0899\n",
      "Epoch 200/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 5.1290 - val_loss: 7.3392\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_size = 32\n",
    "masked_temp_input = layers.Input(shape=(2 * final['State'].nunique(),), dtype=tf.float32, name=\"masked_temp_input\")\n",
    "masked_bool_input = layers.Input(shape=(2 * final['State'].nunique(),), dtype=tf.float32, name=\"masked_bool_input\")\n",
    "masked_lag_input = layers.Input(shape=(2 * final['State'].nunique(),), dtype=tf.float32, name=\"masked_lag_input\")\n",
    "masked_idx_input = layers.Input(shape=(1,), dtype=tf.int32, name=\"masked_idx_input\")\n",
    "coords_input = layers.Input(shape=(2 * final['State'].nunique(), 2,), dtype=tf.float32, name=\"coords_input\")\n",
    "\n",
    "### Step 1: Masked temp input, convert to 32-dim embedding\n",
    "\n",
    "class ExpandInput(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense_1 = layers.TimeDistributed(\n",
    "            layers.Dense(128, activation='relu'), name=\"masked_dense_1\"\n",
    "        )\n",
    "        self.dense_2 = layers.TimeDistributed(\n",
    "            layers.Dense(embedding_size, activation='linear'), name=\"masked_dense_2\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        masked_temp_input = tf.expand_dims(inputs, axis=-1)\n",
    "        masked_temp_hidden = self.dense_1(masked_temp_input)\n",
    "        masked_temp_final = self.dense_2(masked_temp_hidden)\n",
    "        return masked_temp_final\n",
    "\n",
    "masked_temp_final = ExpandInput()(masked_temp_input)\n",
    "\n",
    "### Step 2: Masked bool embedding\n",
    "masked_bool_final = layers.Embedding(input_dim=2, output_dim=embedding_size)(masked_bool_input)\n",
    "\n",
    "### Step 3: Weighted embeddings\n",
    "class WeightedEmbeddings(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        masked_temp_final, masked_bool_final, masked_bool = inputs\n",
    "        masked_bool_expanded = tf.expand_dims(masked_bool, axis=-1)\n",
    "        return masked_temp_final * (1 - masked_bool_expanded) + masked_bool_final * masked_bool_expanded\n",
    "\n",
    "weighted_embeddings = WeightedEmbeddings()([masked_temp_final, masked_bool_final, masked_bool_input])\n",
    "\n",
    "### Step 4: Coordinates, convert to 32-dim embedding\n",
    "\n",
    "class ExpandCoord(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense_1 = layers.TimeDistributed(\n",
    "            layers.Dense(128, activation='relu'), name=\"coord_dense_1\"\n",
    "        )\n",
    "        self.dense_2 = layers.TimeDistributed(\n",
    "            layers.Dense(embedding_size, activation='linear'), name=\"coord_dense_2\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        coords_hidden = self.dense_1(inputs)\n",
    "        coords_final = self.dense_2(coords_hidden)\n",
    "        return coords_final\n",
    "\n",
    "coords_final = ExpandCoord()(coords_input)\n",
    "\n",
    "### Step 5: Masked lag embedding\n",
    "masked_lag_final = layers.Embedding(input_dim=2, output_dim=embedding_size)(masked_lag_input)\n",
    "\n",
    "### Step 6: Combined embeddings and apply dense\n",
    "\n",
    "combined_embedding = layers.Concatenate()([weighted_embeddings, coords_final, masked_lag_final])\n",
    "combined_embedding = layers.Dense(64, activation='relu')(combined_embedding)\n",
    "combined_embedding = layers.Dense(32, activation='linear')(combined_embedding)\n",
    "\n",
    "### Step 7: Apply multi-head attention with dense and layer normalization\n",
    "def apply_attention_layers(embedding_input, num_layers, num_heads=2, key_dim=16, ff_dim=64):\n",
    "\n",
    "    x = embedding_input\n",
    "    for i in range(num_layers):\n",
    "        # Multi-head attention layer\n",
    "        attention_layer = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, name=f\"multi_head_attention_{i+1}\")\n",
    "        attn_output = attention_layer(query=x, value=x, key=x)\n",
    "\n",
    "        # Residual connection + Layer normalization\n",
    "        x = Add()([x, attn_output])\n",
    "        x = LayerNormalization(name=f\"layer_norm_attn_{i+1}\")(x)\n",
    "\n",
    "        # Dense feedforward network\n",
    "        ff_output = Dense(ff_dim, activation='relu', name=f\"dense_ff_{i+1}\")(x)\n",
    "        ff_output = Dense(x.shape[-1], activation='linear', name=f\"dense_ff_linear_{i+1}\")(ff_output)\n",
    "\n",
    "        # Residual connection + Layer normalization\n",
    "        x = Add()([x, ff_output])\n",
    "        x = LayerNormalization(name=f\"layer_norm_ff_{i+1}\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "context_embedding = apply_attention_layers(combined_embedding, num_layers=4)\n",
    "\n",
    "### Step 8: Take embedding corresponding to the masked token\n",
    "\n",
    "class GatherLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        context_embedding, masked_idx_input = inputs\n",
    "        return tf.gather(context_embedding, indices=tf.squeeze(masked_idx_input, axis=-1), batch_dims=1)\n",
    "\n",
    "extracted_embeddings = GatherLayer()([context_embedding, masked_idx_input])\n",
    "\n",
    "### Step 9: Predict the temperature\n",
    "\n",
    "hidden_layer = layers.Dense(128, activation='relu')(extracted_embeddings)\n",
    "hidden_layer = layers.Dense(16, activation='relu')(hidden_layer)\n",
    "output_layer_exp = layers.Dense(1, activation='linear')(hidden_layer)\n",
    "\n",
    "model = Model(inputs=[masked_temp_input, masked_bool_input, masked_idx_input, masked_lag_input, coords_input],\n",
    "              outputs=output_layer_exp)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 1e-3), loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=200,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit the model with validation data and early stopping\n",
    "history = model.fit(\n",
    "    [train_masked_temps, train_masked_bools, train_masked_idxs, train_lag_inds, train_coords],\n",
    "    train_target_temps,\n",
    "    validation_data=([val_masked_temps, val_masked_bools, val_masked_idxs, val_lag_inds, val_coords], val_target_temps),\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2Q-HHWZmvGb",
    "outputId": "54bb2217-d191-4c73-bcd8-f145a21f907a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 127ms/step - loss: 7.9170\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate([test_masked_temps, test_masked_bools, test_masked_idxs, test_lag_inds, test_coords], test_target_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdUxpbQsmx7H",
    "outputId": "7cf6f980-63ed-469c-dae5-3402beff65e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.247624397277832"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
