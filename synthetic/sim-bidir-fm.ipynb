{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ee818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fdaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import copy\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62681fd",
   "metadata": {},
   "source": [
    "1. if movie 2 is watched after movie 1 (doesn't need to be right after), movie 2's rating is N(1, 1). otherwise, movie 2's rating is N(5,1).\n",
    "2. if movie 4 is watched right after movie 3, movie 4's rating N(1,1). if movie 3 is watched right after movie 4, movie 3's rating is N(1,1).\n",
    "3. if movie 5 is watched last, its rating is N(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0879a71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example user order: [2 5 3 1 4]\n",
      "Ratings for the user: [5.47386083 4.36845012 2.08317316 2.87585282 0.98903711]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "N = 10000  # Number of users\n",
    "M = 5  # Number of movies\n",
    "sigma = 1  # Standard deviation for ratings\n",
    "\n",
    "ratings = []  # Ratings for all users\n",
    "orders = []  # Viewing orders for all users\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(N):\n",
    "    order = np.random.permutation(M) + 1 \n",
    "    orders.append(order)\n",
    "    \n",
    "    user_ratings = []\n",
    "    \n",
    "    for j, movie in enumerate(order):\n",
    "        if movie == 2:\n",
    "            # Movie 2 after Movie 1\n",
    "            if 1 in order[:j]:\n",
    "                rating = np.random.normal(1, sigma)\n",
    "            else:\n",
    "                rating = np.random.normal(5, sigma)\n",
    "        \n",
    "        elif movie == 4:\n",
    "            # Movie 4 immediately after Movie 3\n",
    "            if j > 0 and order[j - 1] == 3:\n",
    "                rating = np.random.normal(1, sigma)\n",
    "            else:\n",
    "                rating = np.random.normal(3, sigma)\n",
    "        \n",
    "        elif movie == 3:\n",
    "            # Movie 3 immediately after Movie 4\n",
    "            if j > 0 and order[j - 1] == 4:\n",
    "                rating = np.random.normal(1, sigma)\n",
    "            else:\n",
    "                rating = np.random.normal(3, sigma)\n",
    "        \n",
    "        elif movie == 5:\n",
    "            # Movie 5 watched last\n",
    "            if j == M - 1:\n",
    "                rating = np.random.normal(5, sigma)\n",
    "            else:\n",
    "                rating = np.random.normal(3, sigma)\n",
    "        \n",
    "        else:\n",
    "            # Default rating for other cases\n",
    "            rating = np.random.normal(3, sigma)\n",
    "        \n",
    "        user_ratings.append(rating)\n",
    "    \n",
    "    ratings.append(user_ratings)\n",
    "\n",
    "ratings = np.array(ratings)\n",
    "orders = np.array(orders)\n",
    "\n",
    "# Example output\n",
    "print(\"Example user order:\", orders[0])\n",
    "print(\"Ratings for the user:\", ratings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be35ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Populate the data list\n",
    "for user_id in range(N):\n",
    "    for timestamp, movie_id in enumerate(orders[user_id], start=1):\n",
    "        data.append({\n",
    "            \"user_id\": user_id + 1,\n",
    "            \"movie_id\": movie_id,\n",
    "            \"rating\": ratings[user_id][timestamp - 1],\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b553a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.473861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.368450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.083173</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.875853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989037</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>10000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.627712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.590464</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.267548</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>4.080736</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id    rating  timestamp\n",
       "0            1         2  5.473861          1\n",
       "1            1         5  4.368450          2\n",
       "2            1         3  2.083173          3\n",
       "3            1         1  2.875853          4\n",
       "4            1         4  0.989037          5\n",
       "...        ...       ...       ...        ...\n",
       "49995    10000         4  2.627712          1\n",
       "49996    10000         1  3.590464          2\n",
       "49997    10000         2  0.972798          3\n",
       "49998    10000         3  4.267548          4\n",
       "49999    10000         5  4.080736          5\n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acdf3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['user_id'] <= 7500].reset_index(drop = True)\n",
    "data_test = data[data['user_id'] >= 7501].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a3c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    center = []\n",
    "    movie = []\n",
    "    rating = []\n",
    "    length = []\n",
    "    target = []\n",
    "    \n",
    "    unique_user_ids = df['user_id'].unique()\n",
    "    \n",
    "    for user_id in unique_user_ids:\n",
    "\n",
    "        temp = df[df['user_id'] == user_id]\n",
    "        movie_list, rating_list = list(temp['movie_id']), list(temp['rating'])\n",
    "        center += movie_list\n",
    "        target += rating_list\n",
    "        \n",
    "        for idx in range(temp.shape[0]):\n",
    "            movie.append(movie_list[:idx] + movie_list[(idx+1):])\n",
    "            rating.append(rating_list[:idx] + rating_list[(idx+1):])\n",
    "            length.append(temp.shape[0] - 1)\n",
    "            \n",
    "    return center, movie, rating, length, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d7fcf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "center_train, movie_train, rating_train, length_train, target_train \\\n",
    "    = preprocess_data(data_train)\n",
    "\n",
    "center_test, movie_test, rating_test, length_test, target_test \\\n",
    "    = preprocess_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aead9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_train, center_val, movie_train, movie_val, rating_train, rating_val, \\\n",
    "length_train, length_val, target_train, target_val = train_test_split(\n",
    "    center_train, movie_train, rating_train, length_train, target_train, \n",
    "    test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78e4d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887b5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3714583700680683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d70ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ctx = max(length_train + length_test + length_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47eaa47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_train = [movie + [0] * (max_ctx - len(movie)) if len(movie) < max_ctx \n",
    "               else movie[:max_ctx] for movie in movie_train]\n",
    "\n",
    "movie_val = [movie + [0] * (max_ctx - len(movie)) if len(movie) < max_ctx \n",
    "               else movie[:max_ctx] for movie in movie_val]\n",
    "\n",
    "movie_test = [movie + [0] * (max_ctx - len(movie)) if len(movie) < max_ctx \n",
    "               else movie[:max_ctx] for movie in movie_test]\n",
    "\n",
    "rating_train = [rating + [0] * (max_ctx - len(rating)) if len(rating) < max_ctx \n",
    "               else rating[:max_ctx] for rating in rating_train]\n",
    "\n",
    "rating_val = [rating + [0] * (max_ctx - len(rating)) if len(rating) < max_ctx \n",
    "               else rating[:max_ctx] for rating in rating_val]\n",
    "\n",
    "rating_test = [rating + [0] * (max_ctx - len(rating)) if len(rating) < max_ctx \n",
    "               else rating[:max_ctx] for rating in rating_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a84b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_train_data = np.array(center_train)  # Center movie\n",
    "context_train_data = np.array(movie_train)  # Context movies\n",
    "rating_train_data = np.array(rating_train)  # Context ratings\n",
    "length_train_data = np.array(length_train)  # Length of the context\n",
    "target_train_data = np.array(target_train)  # Target rating\n",
    "\n",
    "center_val_data = np.array(center_val)  # Center movie\n",
    "context_val_data = np.array(movie_val)  # Context movies\n",
    "rating_val_data = np.array(rating_val)  # Context ratings\n",
    "length_val_data = np.array(length_val)  # Length of the context\n",
    "target_val_data = np.array(target_val)  # Target rating\n",
    "\n",
    "center_test_data = np.array(center_test)  # Center movie\n",
    "context_test_data = np.array(movie_test)  # Context movies\n",
    "rating_test_data = np.array(rating_test)  # Context ratings\n",
    "length_test_data = np.array(length_test)  # Length of the context\n",
    "target_test_data = np.array(target_test)  # Target rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e910b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10.3572 - val_loss: 6.5967\n",
      "Epoch 2/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0341 - val_loss: 2.7527\n",
      "Epoch 3/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7673 - val_loss: 2.6820\n",
      "Epoch 4/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6849 - val_loss: 2.6686\n",
      "Epoch 5/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6478 - val_loss: 2.6590\n",
      "Epoch 6/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6705 - val_loss: 2.6513\n",
      "Epoch 7/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6565 - val_loss: 2.6448\n",
      "Epoch 8/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6309 - val_loss: 2.6396\n",
      "Epoch 9/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6788 - val_loss: 2.6362\n",
      "Epoch 10/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6451 - val_loss: 2.6327\n",
      "Epoch 11/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7056 - val_loss: 2.6297\n",
      "Epoch 12/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6174 - val_loss: 2.6279\n",
      "Epoch 13/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6766 - val_loss: 2.6265\n",
      "Epoch 14/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6323 - val_loss: 2.6240\n",
      "Epoch 15/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6302 - val_loss: 2.6227\n",
      "Epoch 16/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6043 - val_loss: 2.6210\n",
      "Epoch 17/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6258 - val_loss: 2.6205\n",
      "Epoch 18/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6018 - val_loss: 2.6186\n",
      "Epoch 19/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6164 - val_loss: 2.6188\n",
      "Epoch 20/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6677 - val_loss: 2.6185\n",
      "Epoch 21/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6763 - val_loss: 2.6174\n",
      "Epoch 22/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6293 - val_loss: 2.6160\n",
      "Epoch 23/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6371 - val_loss: 2.6156\n",
      "Epoch 24/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6505 - val_loss: 2.6153\n",
      "Epoch 25/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6325 - val_loss: 2.6149\n",
      "Epoch 26/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6225 - val_loss: 2.6146\n",
      "Epoch 27/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6150 - val_loss: 2.6142\n",
      "Epoch 28/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6999 - val_loss: 2.6138\n",
      "Epoch 29/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6562 - val_loss: 2.6139\n",
      "Epoch 30/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6332 - val_loss: 2.6136\n",
      "Epoch 31/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6317 - val_loss: 2.6136\n",
      "Epoch 32/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6216 - val_loss: 2.6126\n",
      "Epoch 33/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6338 - val_loss: 2.6121\n",
      "Epoch 34/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6416 - val_loss: 2.6116\n",
      "Epoch 35/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6646 - val_loss: 2.6115\n",
      "Epoch 36/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6209 - val_loss: 2.6114\n",
      "Epoch 37/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6259 - val_loss: 2.6108\n",
      "Epoch 38/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6306 - val_loss: 2.6115\n",
      "Epoch 39/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6252 - val_loss: 2.6109\n",
      "Epoch 40/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6505 - val_loss: 2.6105\n",
      "Epoch 41/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6403 - val_loss: 2.6104\n",
      "Epoch 42/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6437 - val_loss: 2.6103\n",
      "Epoch 43/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6540 - val_loss: 2.6103\n",
      "Epoch 44/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6584 - val_loss: 2.6101\n",
      "Epoch 45/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6577 - val_loss: 2.6098\n",
      "Epoch 46/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6681 - val_loss: 2.6097\n",
      "Epoch 47/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6291 - val_loss: 2.6098\n",
      "Epoch 48/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6397 - val_loss: 2.6093\n",
      "Epoch 49/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6854 - val_loss: 2.6095\n",
      "Epoch 50/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6255 - val_loss: 2.6103\n",
      "Epoch 51/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6513 - val_loss: 2.6105\n",
      "Epoch 52/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6277 - val_loss: 2.6092\n",
      "Epoch 53/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6771 - val_loss: 2.6085\n",
      "Epoch 54/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6537 - val_loss: 2.6087\n",
      "Epoch 55/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6467 - val_loss: 2.6088\n",
      "Epoch 56/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6327 - val_loss: 2.6085\n",
      "Epoch 57/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6281 - val_loss: 2.6088\n",
      "Epoch 58/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6451 - val_loss: 2.6093\n",
      "Epoch 59/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6519 - val_loss: 2.6089\n",
      "Epoch 60/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6384 - val_loss: 2.6086\n",
      "Epoch 61/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6259 - val_loss: 2.6085\n",
      "Epoch 62/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6472 - val_loss: 2.6088\n",
      "Epoch 63/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6281 - val_loss: 2.6089\n",
      "Epoch 64/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6571 - val_loss: 2.6088\n",
      "Epoch 65/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6248 - val_loss: 2.6090\n",
      "Epoch 66/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6141 - val_loss: 2.6080\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6098 - val_loss: 2.6082\n",
      "Epoch 68/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6411 - val_loss: 2.6074\n",
      "Epoch 69/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6770 - val_loss: 2.6081\n",
      "Epoch 70/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6316 - val_loss: 2.6087\n",
      "Epoch 71/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6417 - val_loss: 2.6082\n",
      "Epoch 72/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6325 - val_loss: 2.6079\n",
      "Epoch 73/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6602 - val_loss: 2.6079\n",
      "Epoch 74/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5966 - val_loss: 2.6078\n",
      "Epoch 75/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6234 - val_loss: 2.6084\n",
      "Epoch 76/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6851 - val_loss: 2.6077\n",
      "Epoch 77/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6215 - val_loss: 2.6081\n",
      "Epoch 78/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5995 - val_loss: 2.6072\n",
      "Epoch 79/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6260 - val_loss: 2.6075\n",
      "Epoch 80/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6658 - val_loss: 2.6074\n",
      "Epoch 81/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6363 - val_loss: 2.6090\n",
      "Epoch 82/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6658 - val_loss: 2.6076\n",
      "Epoch 83/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6467 - val_loss: 2.6075\n",
      "Epoch 84/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6487 - val_loss: 2.6076\n",
      "Epoch 85/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6612 - val_loss: 2.6074\n",
      "Epoch 86/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6224 - val_loss: 2.6074\n",
      "Epoch 87/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6668 - val_loss: 2.6072\n",
      "Epoch 88/1000\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6320 - val_loss: 2.6075\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "input_dim = data['movie_id'].nunique() + 1\n",
    "\n",
    "center_input = layers.Input(shape=(1,), dtype=tf.int32, name=\"center_input\")  \n",
    "context_input = layers.Input(shape=(max_ctx,), dtype=tf.int32, name=\"context_input\")  \n",
    "rating_input = layers.Input(shape=(max_ctx,), dtype=tf.float32, name=\"rating_input\")  \n",
    "length_input = layers.Input(shape=(1,), dtype=tf.float32, name=\"length_input\") \n",
    "\n",
    "movie_embedding = layers.Embedding(input_dim=input_dim, output_dim=embedding_size)(context_input)\n",
    "center_embedding = layers.Embedding(input_dim=input_dim, output_dim=embedding_size)(center_input)\n",
    "\n",
    "rating_input = layers.Reshape((max_ctx, 1))(rating_input)\n",
    "weighted_embeddings = layers.Multiply()([movie_embedding, rating_input])\n",
    "\n",
    "sum_embeddings = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1), name=\"sum_embeddings\")(weighted_embeddings)\n",
    "\n",
    "average_embeddings = layers.Lambda(lambda inputs: inputs[0] / inputs[1], name=\"average_embeddings\")(\n",
    "    [sum_embeddings, length_input]\n",
    ")\n",
    "\n",
    "center_embedding_flat = layers.Flatten()(center_embedding)\n",
    "lambda_output = layers.Dot(axes=-1, name=\"dot_product\")([average_embeddings, center_embedding_flat])\n",
    "lambda_output_exp = layers.Activation('linear', name=\"lambda_output_exp\")(lambda_output)\n",
    "\n",
    "model = Model(inputs=[center_input, context_input, rating_input, length_input], outputs=lambda_output_exp)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 1e-4), loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    \n",
    "    patience=10,  \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "# Fit the model with validation data and early stopping\n",
    "history = model.fit(\n",
    "    [center_train_data, context_train_data, rating_train_data, length_train_data], \n",
    "    target_train_data,        \n",
    "    validation_data=([center_val_data, context_val_data, rating_val_data, length_val_data], target_val_data),  \n",
    "    epochs=1000,                 \n",
    "    batch_size=256,            \n",
    "    callbacks=[early_stopping] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a045021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 2.6010\n",
      "Test Loss: 2.636035203933716\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate([center_test_data, context_test_data, rating_test_data, length_test_data], target_test_data)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
